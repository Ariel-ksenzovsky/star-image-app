name: Clean Up Docker Images and S3 Files

on:
    workflow_dispatch: # Manual trigger

jobs:
  delete_old_docker_images:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Log in to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Delete Docker images older than 30 days
        run: |
          echo "Deleting Docker images older than 30 days..."

          # Get the current date and the date 30 days ago
          current_date=$(date +%s)
          cutoff_date=$(date -d '30 days ago' +%s)
          
          # List all Docker images and their creation date
          docker images --format "{{.Repository}}:{{.Tag}} {{.CreatedAt}}" | while read image; do
            # Extract image name and creation date
            image_name=$(echo $image | cut -d' ' -f1)
            created_at=$(echo $image | cut -d' ' -f2-)
            
            # Convert image creation date to timestamp
            image_date=$(date -d "$created_at" +%s)
            
            # Check if the image is older than 30 days
            if [ $image_date -lt $cutoff_date ]; then
              echo "Deleting image: $image_name (Created at: $created_at)"
              docker rmi -f $image_name  # Force remove the old image
            fi
          done

      - name: Verify image deletion
        run: |
          echo "Verifying Docker images are deleted..."
          docker images --format '{{.Repository}}:{{.Tag}}'

  delete_old_s3_files:
    runs-on: ubuntu-latest
    needs: delete_old_docker_images
    steps:
      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: us-east-1  # Specify your AWS region

      - name: List and delete all files older than 30 days from S3 bucket
        run: |
          echo "Deleting all files older than 30 days from S3 bucket..."
          
          # Get the current date and the date 30 days ago
          current_date=$(date +%s)
          cutoff_date=$(date -d '30 days ago' +%s)
          
          # List all files in the S3 bucket
          aws s3 ls s3://${{ secrets.AWS_BUCKET_NAME }}/ --recursive | while read line; do
            # Extract file path and last modified date
            file_path=$(echo $line | awk '{print $4}')
            last_modified=$(echo $line | awk '{print $1" "$2}')
            
            # Convert last modified date to timestamp
            file_date=$(date -d "$last_modified" +%s)
            
            # Check if the file is older than 30 days
            if [ $file_date -lt $cutoff_date ]; then
              echo "Deleting file: $file_path (Last modified: $last_modified)"
              aws s3 rm s3://${{ secrets.AWS_BUCKET_NAME }}/$file_path  # Delete the old file
            fi
          done

      - name: Verify file deletion in S3
        run: |
          echo "Verifying file deletion in S3..."
          aws s3 ls s3://${{ secrets.AWS_BUCKET_NAME }}/ --recursive
